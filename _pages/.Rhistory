help qnorm
help(qnorm)
qnorm(0, 0, 1)
dnorm(0, 0, 1)
pnorm(0, 0, 1)
pnorm(-1, 0, 1)
pnorm(1, 0, 1)
pnorm(-1, 0, 1)
pnorm(-1.02, 0, 1)
rm(list = ls())
library(copula)
library(fGarch) # need for standardized t density
library(MASS) # need for fitdistr and kde2d
library(fCopulae)
library(BatchGetSymbols)
library(dplyr)
library(tidyr)
library(ggplot2)
library(evir)
library(bizdays)
# DATA SETUP ------------------------------------------------------------------
# set tickers
democrat_port = c("APTV","KO","STZ","CSX","EL","EXC","FSLR","F",
"HD","MCD","NEE", "NSC","SPG","SPWR","WMT")
republican_port = c("GOOG","AMZN", "AXP","CVX","C","COP","FB","GILD",
"HON","MRO","MRK","PYPL","QCOM","CRM","V")
num_params = choose(length(democrat_port), 2) + 1
# set dates
cal = create.calendar(name = "mycal", weekdays=c("saturday", "sunday"))
last.date = as.Date("2017-01-31")
first.date = offset("2016-11-08", -50, cal)
bizdays("2020-02-21", "2020-11-02", cal)
offset("2020-02-21", -500, cal)
# first.date = Sys.Date() - 500
# last.date = Sys.Date()
freq.data = 'daily'
calc_log_rets = TRUE
# Read in Data
data = BatchGetSymbols(tickers = democrat_port,
first.date = first.date,
last.date = last.date,
freq.data = freq.data,
cache.folder = file.path(tempdir(),
'BGS_Cache') ) # cache in tempdir()
if (calc_log_rets) {
df = data$df.tickers
df = df[,c("ref.date", "ticker", "price.adjusted")]
data_wide = spread(df, ticker, price.adjusted)
data_wide = data_wide[complete.cases(data_wide),]
rownames(data_wide) = data_wide[,"ref.date"]
data_wide = select(data_wide, -ref.date)
data_wide = apply(data_wide, 2, function(x){diff(log(x))})
} else {
# Construct Data frame of returns per asset
df = data$df.tickers
df = df[,c("ref.date", "ticker", "ret.adjusted.prices")]
data_wide = spread(df, ticker, ret.adjusted.prices)
data_wide = data_wide[complete.cases(data_wide), ]
rownames(data_wide) = data_wide[,"ref.date"]
data_wide = select(data_wide, -ref.date)
data_wide = data_wide[-1,]
}
# Filter Outliers
filter_outlier = function(x) {
iqr = 5 * IQR(x)
ind1 = which(x > iqr + quantile(x, c(0.75)))
ind2 = which(x < -iqr + quantile(x, c(0.25)))
ind = c(ind2, ind1)
x[ind] = NA
x
}
trial = fitdistr(data_wide[,1],"t")$estimate
plot(sort(pstd(data_wide[,1], mean = trial[1], trial[2])))
data_wide = apply(data_wide, 2, filter_outlier)
data_wide = data_wide[complete.cases(data_wide), ]
for (i in 1:15) {
qqnorm(data_wide[,i])
qqline(data_wide[,i])
}
# Generating initial estimate of correlation for t-copula
corr_mat = cor(data_wide,method="spearman")
cor_tau = upper.tri(corr_mat, diag = FALSE)
cor_tau = corr_mat[cor_tau]
# TESTING With some QQ plots --------------------------------------------------
N = nrow(data_wide)
i = 14
dat = sort(data_wide[,i])
split_quant = 0.35
lower_quant = which.min(abs(dat - quantile(dat, split_quant)))
# Fit GPD to lower tail
u = quantile(-dat, c(1 - split_quant))
gpd_est = gpd(-dat, threshold = u, method = c("ml"),
information = c("observed"))
beta = gpd_est$par.ests[2]
xi = gpd_est$par.ests[1]
tailplot(gpd_est)
# TESTING TAIL PROBS --------------------
x = gpd_est
dat1 <- as.numeric(gpd_est$data)
threshold <- x$threshold
plotmin <- threshold
extend = 1.5
plotmax <- max(dat1) * extend
xx <- seq(from = 0, to = 1, length = 1000)
z <- qgpd(xx, xi, threshold, beta)
z <- pmax(pmin(z, plotmax), plotmin)
y <- pgpd(z, xi, threshold, beta)
prob <- x$p.less.thresh
y <- (1 - prob) * (1 - y)
y = sort(sample(y, size =lower_quant), decreasing = FALSE)
est = as.numeric(fitdistr(dat[(lower_quant+1):length(dat)],"t")$estimate)
est[2] = est[2]*sqrt(est[3] / (est[3]-2))
t_cdf = (1 - split_quant) * pstd(dat[(lower_quant+1):length(dat)], mean = est[1],
sd = est[2], nu = est[3]) + split_quant
plot(c(y, t_cdf))
N = length(dat[(lower_quant+1):length(dat)])
quantv = (1/ (N + 1)) * seq(1,N,1)
qqplot(qt(quantv, est[3]), sort(dat[(lower_quant+1):length(dat)]),
main='Nasdaq - QQ plot for t-dist',xlab='theoretical quantiles - t',
ylab='empirical quantiles')
abline(lm(quantile(dat[(lower_quant+1):length(dat)],
c(.25,.75))~qt(c(.25,.75), est[3])))
qqnorm(data_wide[,14])
qqline(data_wide[,14])
N = nrow(data_wide)
i = 14
dat = sort(data_wide[,i])
split_quant = 0.35
lower_quant = which.min(abs(dat - quantile(dat, split_quant)))
# Fit GPD to lower tail
u = quantile(-dat, c(1 - split_quant))
gpd_est = gpd(-dat, threshold = u, method = c("ml"),
information = c("observed"))
beta = gpd_est$par.ests[2]
xi = gpd_est$par.ests[1]
tailplot(gpd_est)
# TESTING TAIL PROBS --------------------
x = gpd_est
dat1 <- as.numeric(gpd_est$data)
threshold <- x$threshold
plotmin <- threshold
extend = 1.5
plotmax <- max(dat1) * extend
xx <- seq(from = 0, to = 1, length = 1000)
z <- qgpd(xx, xi, threshold, beta)
z <- pmax(pmin(z, plotmax), plotmin)
y <- pgpd(z, xi, threshold, beta)
prob <- x$p.less.thresh
y <- (1 - prob) * (1 - y)
y = sort(sample(y, size =lower_quant), decreasing = FALSE)
#est = as.numeric(fitdistr(dat[(lower_quant+1):length(dat)],"t")$estimate)
est = as.numeric(fitdistr(dat,"t")$estimate)
est[2] = est[2]*sqrt(est[3] / (est[3]-2))
t_cdf = pstd(dat[(lower_quant+1):length(cdf)], mean = est[1],
sd = est[2], nu = est[3])
#t_cdf = (1 - split_quant) * pstd(dat[(lower_quant+1):length(dat)], mean = est[1],
#                                 sd = est[2], nu = est[3]) + split_quant
plot(c(y, t_cdf))
est = as.numeric(fitdistr(dat,"t")$estimate)
est[2] = est[2]*sqrt(est[3] / (est[3]-2))
t_cdf = pstd(dat[(lower_quant+1):length(dat)], mean = est[1],
sd = est[2], nu = est[3])
plot(c(y, t_cdf))
quantv = (1/ (N + 1)) * seq(1,N,1)
qqplot(qt(quantv, est[3]), sort(dat[(lower_quant+1):length(dat)]),
main='Nasdaq - QQ plot for t-dist',xlab='theoretical quantiles - t',
ylab='empirical quantiles')
abline(lm(quantile(dat[(lower_quant+1):length(dat)],
c(.25,.75))~qt(c(.25,.75), est[3])))
qqnorm(data_wide[,14])
qqline(data_wide[,14])
# Fit a t-distribution to each asset ------------------------------------------
# Prepare to fit copula
data1 = data.frame(data_wide[,1])
i = 1
for (col in colnames(data_wide)) {
dat = sort(data_wide[,i])
split_quant = (which(dat > 0)[1] - 2) / length(dat) # Fraction of data to split
lower_quant = which.min(abs(dat - quantile(dat, split_quant)))
# Fit GPD to lower tail
u = quantile(-dat, c(1 - split_quant))
gpd_est = gpd(-dat, threshold = u, method = c("ml"),
information = c("observed"))
beta = gpd_est$par.ests[2]
xi = gpd_est$par.ests[1]
# Convert upper tail negative returns to lower tail returns
x = gpd_est
dat1 <- as.numeric(gpd_est$data)
threshold <- x$threshold
plotmin <- threshold
extend = 1.5
plotmax <- max(dat1) * extend
xx <- seq(from = 0, to = 1, length = 1000)
z <- qgpd(xx, xi, threshold, beta)
z <- pmax(pmin(z, plotmax), plotmin)
y <- pgpd(z, xi, threshold, beta)
prob <- x$p.less.thresh
y <- (1 - prob) * (1 - y)
y = sort(sample(y, size =lower_quant), decreasing = FALSE)
# Estimate t-dsitribution
# est = as.numeric(fitdistr(dat[(lower_quant+1):length(dat)],"t")$estimate)
est = as.numeric(fitdistr(dat,"t")$estimate)
est[3] = max(2.1, est[3])
est[2] = est[2]*sqrt(est[3] / (est[3]-2))
t_cdf = pstd(dat[(lower_quant+1):length(dat)],
mean = est[1], sd = est[2], nu = est[3])
#t_cdf = (1 - split_quant) * pstd(dat[(lower_quant+1):length(dat)], mean = est[1],
#                                sd = est[2], nu = est[3]) + split_quant
temp = data.frame(col = c(y, t_cdf))
colnames(temp) = col
data1 = cbind(data1, temp)
i = i + 1
}
data1 = data1[,-1]
plot(data1[,1])
plot(data1[,2])
plot(data1[,3])
plot(data1[,4])
plot(data1[,5])
plot(data1[,6])
plot(data1[,7])
plot(data1[,8])
plot(data1[,9])
plot(data1[,10])
plot(data1[,11])
plot(data1[,12])
plot(data1[,13])
plot(data1[,14])
## THIS STEP TAKES ABOUT 5-10 MINUTES ----------------------------------------
# Fit t-copula, Note: choose(15,2) + 1 parameters to be estimated
cop_t_dim2 = tCopula(cor_tau, dim = nrow(corr_mat), dispstr = "un", df = 50)
ft1 = fitCopula(cop_t_dim2, data = data1,
method = "ml",
start = c(rep(0, length(cor_tau)), 50))
# ----------------------------------------------------------------------------
# Set up graph for simulations -----------
election_ind = which(rownames(data_wide) %in% c("2016-11-08"))
draws = nrow(data_wide) - election_ind
capital = 1e6
# Build cumulative returns of original series before the election
real_rets = cumprod(1 + rowMeans(exp(data_wide) - 1))
df_plot = data.frame(time = 1:length(real_rets), y = real_rets)
# Generate plot of cumulative returns
s = ggplot(df_plot, aes(x = time, y = y)) +
geom_line(colour = "darkred")
# Generate multiple paths after election --------------------------------------
num_paths = 300
n = length(ft1@estimate)
rhos = ft1@estimate[1:n-1]
nu = ft1@estimate[n]
# q_split = 0.25
# data3 contains column vectors of return paths
data3 = data.frame(data_wide[1:draws,1])
for (path in 1:num_paths) {
# Generate Random Variates from our copula
ct = tCopula(rhos, dim = nrow(corr_mat), dispstr = "un", df = nu)
uvsim = rCopula(draws, ct)
# Recover simulation values based on inverse transformation
data2 = data.frame(data_wide[1:draws,1])
for (i in 1:nrow(corr_mat)) {
# Re-estimate the data with our distributions
dat = sort(data_wide[(nrow(data_wide) - 55):nrow(data_wide), i])
q_split = (which(dat > 0)[1] - 2) / length(dat)
# Set lower and upper indices to be estimated by both distributions
gpd_ind = which(uvsim[, i] <= q_split)
t_ind = which(uvsim[, i] > q_split)
# Split simulations
g_dat = (1 - uvsim[gpd_ind, i] - (1 - q_split)) / q_split # this is done to estimate upper tail of returns
t_dat = (uvsim[t_ind, i] - q_split) / (1 - q_split)
temp = rep(0, length(uvsim[, i]))
lower_quant = which.min(abs(dat - quantile(dat, q_split)))
# Fit t to upper tail
est = as.numeric(fitdistr(dat[(lower_quant+1):length(dat)],"t")$estimate)
est[3] = max(2.1, est[3])
est[2] = est[2]*sqrt(est[3] / (est[3] - 2))
temp[t_ind] = qstd(t_dat, mean = est[1], sd = est[2],
nu = est[3])
# Fit GPD to lower tail
u = quantile(-dat, c(1 - q_split))
gpd_est = gpd(-dat, threshold = u, method = c("ml"),
information = c("observed"))
beta = gpd_est$par.ests[2]
xi = gpd_est$par.ests[1]
temp[gpd_ind] = -qgpd(g_dat, xi = xi, mu=u, beta=beta)
temp = data.frame(col = exp(temp) - 1)
colnames(temp) = colnames(data_wide)[i]
data2 = cbind(data2, temp)
}
data2 = data2[,-1]
# Look at Cumulative returns, before and after simulation
sim_returns = cumprod(1 + rowMeans(data2)) * real_rets[election_ind]
data3 = cbind(data3, sim_returns)
total = length(real_rets) + draws
#color = c("black", "steelblue")
#color = sample(color, size = 1, prob = c(0.5, 0.5))
color = "steelblue"
# Make all vectors of equal size
sim_returns = c(rep(NA, election_ind -1),
c(real_rets[election_ind], sim_returns))
df_plot_sim = data.frame(time = 1:length(sim_returns), z = sim_returns)
s = s + geom_line(data = df_plot_sim,
aes(x = time, y = z), colour = color, alpha = 0.3)
}
data3 = data3[,-1]
# Check distribution of final outcomes ----------------------------------------
library(moments)
trial = as.numeric(data3[nrow(data3),])
qqnorm(trial)
qqline(trial)
skewness(trial)
kurtosis(trial)
shapiro.test(trial)
shapiro.test(rnorm(200))
s
uvsim[t_ind, i]
q_split
# Set up graph for simulations -----------
election_ind = which(rownames(data_wide) %in% c("2016-11-08"))
draws = nrow(data_wide) - election_ind
capital = 1e6
# Build cumulative returns of original series before the election
real_rets = cumprod(1 + rowMeans(exp(data_wide) - 1))
df_plot = data.frame(time = 1:length(real_rets), y = real_rets)
# Generate plot of cumulative returns
s = ggplot(df_plot, aes(x = time, y = y)) +
geom_line(colour = "darkred")
# Generate multiple paths after election --------------------------------------
num_paths = 300
n = length(ft1@estimate)
rhos = ft1@estimate[1:n-1]
nu = ft1@estimate[n]
# q_split = 0.25
# data3 contains column vectors of return paths
data3 = data.frame(data_wide[1:draws,1])
for (path in 1:num_paths) {
# Generate Random Variates from our copula
ct = tCopula(rhos, dim = nrow(corr_mat), dispstr = "un", df = nu)
uvsim = rCopula(draws, ct)
# Recover simulation values based on inverse transformation
data2 = data.frame(data_wide[1:draws,1])
for (i in 1:nrow(corr_mat)) {
# Re-estimate the data with our distributions
dat = sort(data_wide[(nrow(data_wide) - 55):nrow(data_wide), i])
q_split = (which(dat > 0)[1] - 2) / length(dat)
# Set lower and upper indices to be estimated by both distributions
gpd_ind = which(uvsim[, i] <= q_split)
t_ind = which(uvsim[, i] > q_split)
# Split simulations
g_dat = (1 - uvsim[gpd_ind, i] - (1 - q_split)) / q_split # this is done to estimate upper tail of returns
t_dat = (uvsim[t_ind, i] - q_split) / (1 - q_split)
temp = rep(0, length(uvsim[, i]))
lower_quant = which.min(abs(dat - quantile(dat, q_split)))
# Fit t to upper tail
#est = as.numeric(fitdistr(dat[(lower_quant+1):length(dat)],"t")$estimate)
est = as.numeric(fitdistr(dat,"t")$estimate)
est[3] = max(2.1, est[3])
est[2] = est[2]*sqrt(est[3] / (est[3] - 2))
temp[t_ind] = qstd(uvsim[t_ind, i], mean = est[1], sd = est[2], nu = est[3])
#temp[t_ind] = qstd(t_dat, mean = est[1], sd = est[2],
#                  nu = est[3])
# Fit GPD to lower tail
u = quantile(-dat, c(1 - q_split))
gpd_est = gpd(-dat, threshold = u, method = c("ml"),
information = c("observed"))
beta = gpd_est$par.ests[2]
xi = gpd_est$par.ests[1]
temp[gpd_ind] = -qgpd(g_dat, xi = xi, mu=u, beta=beta)
temp = data.frame(col = exp(temp) - 1)
colnames(temp) = colnames(data_wide)[i]
data2 = cbind(data2, temp)
}
data2 = data2[,-1]
# Look at Cumulative returns, before and after simulation
sim_returns = cumprod(1 + rowMeans(data2)) * real_rets[election_ind]
data3 = cbind(data3, sim_returns)
total = length(real_rets) + draws
#color = c("black", "steelblue")
#color = sample(color, size = 1, prob = c(0.5, 0.5))
color = "steelblue"
# Make all vectors of equal size
sim_returns = c(rep(NA, election_ind -1),
c(real_rets[election_ind], sim_returns))
df_plot_sim = data.frame(time = 1:length(sim_returns), z = sim_returns)
s = s + geom_line(data = df_plot_sim,
aes(x = time, y = z), colour = color, alpha = 0.3)
}
data3 = data3[,-1]
s
library(moments)
trial = as.numeric(data3[nrow(data3),])
qqnorm(trial)
qqline(trial)
skewness(trial)
kurtosis(trial)
mean(trial)
sd(trial)
skewness(trial)
kurtosis(triaal)
kurtosis(trial)
s
list(data3, s, ft1)
testing = list(data3, s, ft1)
testing[1]
testing[2]
testing[3]
capture.output(list(data3, s, ft1))
save(list(data3, s, ft1), file = "trump_demo.Rdata")
save(data3, s, ft1, file = "trump_demo.Rdata")
data3 = data3[,-1]
data4 = data3 / real_rets[election_ind]
save(data1, data4, s, ft1, file = "trump_demo.Rdata")
