{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israeldi/quantlab/master/assets/images/Program-Logo.png\" width=\"400px\" align=\"right\">\n",
    "\n",
    "## Introduction - Measuring Market Risk in Python \n",
    "### [(Go to Quant Lab)](https://israeldi.github.io/quantlab/)\n",
    "\n",
    "#### Source: https://github.com/playgrdstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAR or ES are common terms that one would usually come across in finance when it comes to the measurement of market risks.\n",
    "\n",
    "VAR, or Value At Risk, is basically a measure of the potential losses that one could face, at a specific level of confidence - e.g. 99%. But before we get into VAR, we first need to discuss what value we are assessing risk against. What we want to measure would be the change in market prices over a time period (e.g. day to day). So what VAR would then tell us then would be how much we could lose (or gain) due to the change in prices.\n",
    "\n",
    "It's quite common to use lognormal instead of normal returns when computing the change in prices. Useful links which provide more information on the difference between the two -\n",
    "\n",
    "- https://quantivity.wordpress.com/2011/02/21/why-log-returns/\n",
    "- http://www.insight-things.com/log-normal-distribution-mistaken\n",
    "\n",
    "We will compute relative returns and lognormal returns for FX and equity prices. As daily returns are not large, the difference for FX is close to indiscernible, and just slightly for equity returns.\n",
    "\n",
    "We will use FX and equity data freely available from Quandl. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create free Quandl account\n",
    "\n",
    "1. Go to [Quandl](https://www.quandl.com) and create a free account.\n",
    "2. Retrive your API key from your profile\n",
    "3. Open **Terminal** and install quandl: `pip install quandl` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your own key from Quandl and add here\n",
    "quandl.ApiConfig.api_key = \"nN5mnpi_zxaiJp7u3Yii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_list = ['CUR/JPY', 'CUR/GBP', \n",
    "           'CUR/EUR', 'CUR/CHF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.datetime(2011,1,1)\n",
    "end_ = pd.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start, end_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_DF = pd.DataFrame(index=dates)\n",
    "for code in fx_list:\n",
    "    FX_DF[code] = quandl.get(code, start_date=start, end_date=end_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just plot the distribution of actual price levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX_DF.hist(bins=20, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Equities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_list = ['EOD/MSFT', 'EOD/AAPL', 'EOD/MMM', 'EOD/MCD']\n",
    "EQ_DF = pd.DataFrame(index=dates)\n",
    "for code in eq_list:\n",
    "    EQ_DF[code] = quandl.get(code, start_date=start, end_date=end_).Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_DF.hist(bins=20, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_Returns = (EQ_DF / EQ_DF.shift(10)) - 1\n",
    "EQ_Returns.hist(bins=20, range=(-0.05, 0.05), figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EQ_DF_LogReturns = np.log(EQ_DF / EQ_DF.shift(10))\n",
    "EQ_DF_LogReturns.hist(bins=20, range=(-0.05, 0.05), figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value at Risk ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Asset\n",
    "\n",
    "There's nothing very complicated about Value at Risk (VAR). To put it simply, it's simply a single metric that shows the potential losses of a portfolio etc (at different confidence levels). There are three main methods to compute VAR -\n",
    "* Parametric\n",
    "* Historical\n",
    "* Monte Carlo\n",
    "\n",
    "**Parametric VAR**\n",
    "\n",
    "Very often, the parametric VAR is based on a normal distribution. Plotting a normal distribution and the VAR on a chart will give us a good overview of how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use z to define how many standard deviations away from the mean\n",
    "# Here we use z = -2.33 to get to a 99% confidence interval. Why 99% will be obvious once we plot out the distribution\n",
    "z = -2.33\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# plotting the normal distribution, using the scipy stats norm function\n",
    "plt.ylim(0, 0.5)\n",
    "x = np.arange(-5,5,0.1)\n",
    "y1 = stats.norm.pdf(x)\n",
    "plt.plot(x, y1)\n",
    "\n",
    "x2 = np.arange(-5, z, 0.01) # we use this range from the -ve end to -2.33 to compute the area\n",
    "sum_ = 0\n",
    "# s = np.arange(-10,z,0.01)\n",
    "for i in x2:\n",
    "    sum_ += stats.norm.pdf(i) * 0.01 # computing area under graph from -5 to -2.33 in steps of 0.01\n",
    "\n",
    "plt.annotate('Area is ' + str(round(sum_,3)), xy = (z-1.3, 0.05), fontsize=12)\n",
    "plt.annotate('z=' + str(z), xy=(z, 0.01), fontsize=12)\n",
    "plt.fill_between(x2, stats.norm.pdf(x2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you understand what VAR and confidence levels mean (from the chart above), getting the $Z$ for different confidence levels is simple, and is the basis for computing parametric VAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_95 = stats.norm.ppf(1 - 0.95)\n",
    "z_99 = stats.norm.ppf(1 - 0.99)\n",
    "z_999 = stats.norm.ppf(1 - 0.999)\n",
    "\n",
    "print('95%, 99%, 99.9% Z =', z_95, z_99, z_999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\alpha$ be the confidence level, then the $N$-day VaR is given by:\n",
    "> $VAR_N = \\varPhi^{-1}(1-\\alpha) * \\sigma_V * \\sqrt{N}$\n",
    "\n",
    "If we are working with returns, then the formula becomes:\n",
    "> $VAR_N = position * (-\\mu_V + \\varPhi^{-1}(1-\\alpha)*\\sigma_V) * \\sqrt{N}$\n",
    "\n",
    "If mean return is close 0, then we can drop this term from the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start = pd.datetime(2011,1,1)\n",
    "end_ = pd.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Price data from AAPL\n",
    "AAPL = quandl.get('EOD/AAPL', start_date=start, end_date=end_).Close\n",
    "\n",
    "rets_1 = (AAPL / AAPL.shift(1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s get market prices of AAPL from Quandl again, and compute the returns.\n",
    "We shall compute the mean and standard deviation of the AAPL returns first as we will use this later to perform Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(rets_1)\n",
    "std = np.std(rets_1)\n",
    "Z_99 = stats.norm.ppf(1 - 0.99)\n",
    "price = AAPL.iloc[-1]\n",
    "\n",
    "print(mean, std, Z_99, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s compute the parametric and historical VAR numbers so we have a basis for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParamVAR = price * Z_99 * std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historical VaR**\n",
    "\n",
    "Historical VAR is even simpler. We simply get the return at the right percentile and apply the same formula to the latest prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HistVAR = price * np.percentile(rets_1.dropna(), 1)\n",
    "\n",
    "print('Parametric VAR is {0:.3f} and Historical VAR is {1:.3f}'.format(ParamVAR, HistVAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monte Carlo**\n",
    "\n",
    "For Monte Carlo simulation, we simply apply a simulation using the assumptions of normality, and the mean and std computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_sims = 1000000\n",
    "sim_returns = np.random.normal(mean, std, n_sims)\n",
    "SimVAR = price * np.percentile(sim_returns, 1)\n",
    "print('Simulated VAR is ', SimVAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Assets\n",
    "\n",
    "**Parametric VAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the VAR for the equity prices we obtained from Quandl earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.99\n",
    "Z = stats.norm.ppf(1 - confidence)\n",
    "mean = np.mean(EQ_Returns)\n",
    "stddev = np.std(EQ_Returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAR for the latest prices is then ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_DF.dropna().iloc[-1,:] * Z *stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historical VAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EQ_DF.dropna().iloc[-1,:] * np.percentile(EQ_Returns.dropna(), 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
